{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66cd1a49-0c45-487e-b80a-6687da8517d9",
   "metadata": {},
   "source": [
    "# Team Raj Datathon 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e87ef-a8a3-4b4d-81eb-8b57605afcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d4e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in data\n",
    "visitation_df=pd.read_csv('data/visitation_data.csv')\n",
    "climate_df=pd.read_csv('data/climate_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cleaning visitors data\n",
    "DATA_DIR = Path(\"data\")\n",
    "VIS_CSV = DATA_DIR / \"data/visitation_data.csv\"\n",
    "OUT_TIDY = DATA_DIR / \"visitation_tidy_imputed.csv\" \n",
    "\n",
    "# ---------- 1) load ----------\n",
    "df = pd.read_csv(VIS_CSV)\n",
    "\n",
    "# column names\n",
    "df.columns = (\n",
    "    df.columns.str.strip()\n",
    "              .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "              .str.replace(\".\", \"\", regex=False)  # remove literal dots from \"Mt. Buller\"\n",
    "              .str.lower()\n",
    ")\n",
    "# expect: year, week, mt_baw_baw, mt_stirling, ..., charlotte_pass\n",
    "\n",
    "# ---------- 3) reshape to tidy ----------\n",
    "id_cols = [\"year\", \"week\"]\n",
    "value_cols = [c for c in df.columns if c not in id_cols]\n",
    "vis = df.melt(id_vars=id_cols, value_vars=value_cols,\n",
    "              var_name=\"resort\", value_name=\"visitors\")\n",
    "\n",
    "# clean resort labels & ensure numeric visitors\n",
    "vis[\"resort\"] = vis[\"resort\"].str.replace(\"_\", \" \").str.title()\n",
    "vis[\"visitors\"] = pd.to_numeric(vis[\"visitors\"], errors=\"coerce\").clip(lower=0)\n",
    "\n",
    "\n",
    "# REPLACING 202O W10-15 VALUES WITH AVERGAE OF THE PREVIOUS YEAR SAME WEEK AND THE WEEK BEFORE FROM A LOCATION\n",
    "\n",
    "# ensure numeric & float during imputation\n",
    "vis[\"visitors\"] = pd.to_numeric(vis[\"visitors\"], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "# Base lookup table\n",
    "base = vis[[\"year\", \"week\", \"resort\", \"visitors\"]].copy()\n",
    "\n",
    "# 1) Prev year, same week\n",
    "prev_same = base.rename(columns={\"year\":\"py_year\",\"week\":\"py_week\",\"visitors\":\"v_prev_same\"})\n",
    "m1 = vis.copy()\n",
    "m1[\"year_minus1\"] = m1[\"year\"] - 1\n",
    "m1 = m1.merge(\n",
    "    prev_same,\n",
    "    left_on=[\"resort\",\"year_minus1\",\"week\"],\n",
    "    right_on=[\"resort\",\"py_year\",\"py_week\"],\n",
    "    how=\"left\"\n",
    ").drop(columns=[\"py_year\",\"py_week\"])\n",
    "\n",
    "# 2) Prev year, week-1  (week 1 -> 0 won’t match; that’s OK)\n",
    "prev_before = base.rename(columns={\"year\":\"py_year2\",\"week\":\"py_week2\",\"visitors\":\"v_prev_before\"})\n",
    "m1[\"week_minus1\"] = m1[\"week\"] - 1\n",
    "m2 = m1.merge(\n",
    "    prev_before,\n",
    "    left_on=[\"resort\",\"year_minus1\",\"week_minus1\"],\n",
    "    right_on=[\"resort\",\"py_year2\",\"py_week2\"],\n",
    "    how=\"left\"\n",
    ").drop(columns=[\"py_year2\",\"py_week2\"])\n",
    "\n",
    "# 3) Row-wise mean of available previous-year values (no numpy vstack)\n",
    "m2[\"imputed_prev_year_mean\"] = (\n",
    "    pd.concat([m2[\"v_prev_same\"], m2[\"v_prev_before\"]], axis=1)\n",
    "      .mean(axis=1, skipna=True)   # returns float; no warnings\n",
    ")\n",
    " \n",
    "# 4) Replace zeros where we have an imputed value (keep dtype float here)\n",
    "mask_zero = m2[\"visitors\"].eq(0)\n",
    "mask_have = m2[\"imputed_prev_year_mean\"].notna()\n",
    "m2.loc[mask_zero & mask_have, \"visitors\"] = m2.loc[mask_zero & mask_have, \"imputed_prev_year_mean\"]\n",
    "\n",
    "# Commit back to vis (still float)\n",
    "vis = m2[[\"year\",\"week\",\"resort\",\"visitors\"]].copy()\n",
    "\n",
    "# FOR THE FIRST YEAR, DONT HAVE PREVIOUS YEAR DATA, SO TOOK AVERAGE OF THE PAST 2 WEEKS FOR CURRENT WEEK\n",
    "def fill_first_year_with_prev2weeks(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.sort_values([\"resort\",\"year\",\"week\"]).copy()\n",
    "    first_year = df[\"year\"].min()\n",
    "    target = (df[\"year\"] == first_year) & (df[\"visitors\"] == 0)\n",
    "    for idx, row in df[target].iterrows():\n",
    "        r, y, w = row[\"resort\"], int(row[\"year\"]), int(row[\"week\"])\n",
    "        prev = df[(df[\"resort\"]==r) & (df[\"year\"]==y) & (df[\"week\"].between(w-2, w-1))][\"visitors\"]\n",
    "        if len(prev) > 0:\n",
    "            df.at[idx, \"visitors\"] = prev.mean()   # float assign is OK\n",
    "    return df\n",
    "\n",
    "vis = fill_first_year_with_prev2weeks(vis)\n",
    "\n",
    "# ---------- FINALIZE DTYPE ----------\n",
    "# Only after all imputations: round and cast to Int64 (nullable)\n",
    "vis[\"visitors\"] = vis[\"visitors\"].round().astype(\"Int64\")\n",
    "print(\"Remaining zeros after imputation:\", int((vis[\"visitors\"] == 0).sum()))\n",
    "\n",
    "# Diff log: which zeros changed?\n",
    "before = df.melt(id_vars=[\"year\",\"week\"],\n",
    "                 value_vars=[c for c in df.columns if c not in [\"year\",\"week\"]],\n",
    "                 var_name=\"resort\", value_name=\"visitors_before\")\n",
    "before[\"resort\"] = before[\"resort\"].str.replace(\"_\",\" \").str.title()\n",
    "\n",
    "chg = vis.merge(before, on=[\"year\",\"week\",\"resort\"], how=\"left\")\n",
    "changed = chg[(chg[\"visitors_before\"] == 0) & (chg[\"visitors\"].notna()) & (chg[\"visitors\"] != 0)]\n",
    "print(f\"Replacements made: {len(changed)}\")\n",
    "print(changed.head(20)[[\"resort\",\"year\",\"week\",\"visitors_before\",\"visitors\"]])\n",
    "\n",
    "\n",
    "vis.to_csv(\"data/visitation_tidy_imputed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341a4193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1210\n"
     ]
    }
   ],
   "source": [
    "# cleaning climate data\n",
    "\n",
    "# trim pre-2014 data\n",
    "climate_filtered_df = climate_df[climate_df['Year'] >= 2014]\n",
    "\n",
    "# get ONLY snow seasons for each year\n",
    "climate_filtered_df = climate_filtered_df[\n",
    "    ((climate_filtered_df['Month'] == 6) & (climate_filtered_df['Day'] >= 9)) |\n",
    "    ((climate_filtered_df['Month'].isin([7,8]   ))) | \n",
    "    ((climate_filtered_df['Month'] == 9) & (climate_filtered_df['Day'] <= 21))\n",
    "    ]\n",
    "\n",
    "# datetime processing\n",
    "climate_filtered_df['Date'] = pd.to_datetime(\n",
    "    dict(year=2000, month=climate_filtered_df['Month'], day=climate_filtered_df['Day'])\n",
    ")\n",
    "\n",
    "# adding a week column for each date\n",
    "start_date = pd.Timestamp(year=2000, month=6, day=9)\n",
    "climate_filtered_df['DaysSinceJune9'] = (climate_filtered_df['Date'] - start_date).dt.days\n",
    "climate_filtered_df['Week'] = (climate_filtered_df['DaysSinceJune9'] // 7) + 1\n",
    "climate_filtered_df.drop(columns='DaysSinceJune9', inplace=True)\n",
    "climate_filtered_df.drop(columns='Date', inplace=True)\n",
    "\n",
    "# averaging over each week\n",
    "week_av_clim_df = climate_filtered_df.groupby(\n",
    "    ['Bureau of Meteorology station number', 'Year', 'Week']\n",
    "    ) [[\n",
    "        'Maximum temperature (Degree C)',\n",
    "        'Minimum temperature (Degree C)',\n",
    "        'Rainfall amount (millimetres)'\n",
    "    ]].mean().reset_index()\n",
    "\n",
    "# deal with remaining NaN that weren't removed by averaging over each week\n",
    "# imputing on median (reduces impact of outlier weather conditions)  \n",
    "\n",
    "cols_to_fill = [\n",
    "    'Maximum temperature (Degree C)',\n",
    "    'Minimum temperature (Degree C)',\n",
    "    'Rainfall amount (millimetres)'\n",
    "]\n",
    "\n",
    "station_week_clim_avg = week_av_clim_df.groupby(['Bureau of Meteorology station number', 'Week'])[cols_to_fill].transform('median')\n",
    "week_av_clim_df[cols_to_fill] = week_av_clim_df[cols_to_fill].fillna(station_week_clim_avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
